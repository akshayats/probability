{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Kronecker Graphical Models - A Finite Mixture Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose the mixture model below for stochastic kronecker graph solutions\n",
    "\n",
    "<img src=\"mix_model.png\" style=\"width: 30%\" align=\"right\">\n",
    "\n",
    "- Notation Glossary:  \n",
    "    - $K$ : Number of kronecker layers or products to obtain $\\Phi$\n",
    "    - $N$ : Number of rows (=columns)\n",
    "    - $\\gamma_\\alpha$, $\\gamma_\\beta$\n",
    "    - $\\alpha_k$, $\\beta_k$\n",
    "    - $\\mu_k$\n",
    "    - $\\theta_{ij}$\n",
    "    - $\\Sigma$\n",
    "    - $\\epsilon$\n",
    "    - $n_{ij}$\n",
    "    - $Z$\n",
    "    - $U$\n",
    "    - $\\Phi$\n",
    "    - $G$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further thoughts and ideas\n",
    "1. The noise addition could be to the kronecker result, not to each theta. This would mean that whatever the type of $\\Phi$ we learn or use, we cannot be more certain than the variance of the noise we add to the kronecker product. This will stop islands from occuring. (How do we write that in a graphical representation?)\n",
    "\n",
    "2. Should we be learning a transition matrix for $\\theta_{ij}$ elements? There ought to be some model over the structure of $\\theta^{(k)}_c$. However, a transition is a valid model for only sequences, this is not a sequence..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will implement our mixture model and generate examples from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods being used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kronecker_product(mat1, mat2):\n",
    "    m1 = tf.shape(mat1)[0]\n",
    "    n1 = tf.size(mat1) // m1\n",
    "    m2 = tf.shape(mat2)[0]\n",
    "    n2 = tf.size(mat2) // m2\n",
    "    mat2_rsh =tf.reshape(mat1, [1, m1, 1, n1])\n",
    "    mat1_rsh =tf.reshape(mat2, [m2, 1, n2, 1])\n",
    "    return tf.reshape(mat1_rsh*mat2_rsh, [m1 * m2, n1 * n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise2Mat(mat, mean=0, std=0.01, NRMLZ=True):\n",
    "    # Set the seed so the results are reproducible.\n",
    "    np.random.seed(123)\n",
    "    # Make distribution, sample and add\n",
    "    p_eta = tfd.Normal(loc=mean, scale=std, name='AdditiveEdgeNoise')\n",
    "    eta_c = p_eta.sample(tf.shape(mat))\n",
    "    mat_noise = mat + eta_c\n",
    "    # Make sure values do not run off\n",
    "    # Clip values out of [0,1]\n",
    "    if NRMLZ:\n",
    "        mat_noise_nrml   = tf.maximum(tf.minimum(mat_noise,1),0)\n",
    "        return mat_noise_nrml\n",
    "    else:\n",
    "        return mat_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_shape_   = np.array([3,3])\n",
    "# alpha_         = [1.0]\n",
    "# beta_          = [1.0]\n",
    "K_             = 5\n",
    "NoiseScale_    = 0.1\n",
    "\n",
    "# Run Parameters\n",
    "NumSamples    = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture Model implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mixture model still uses the layered network structure proposed in the work of Stochastic Kronecker Graphs. It relaxes the assumption that the $\\theta$ at every kronecker layer is the same. Which means the following:\n",
    "\n",
    "* $G$ is the adjacency matrix of a large network whose size is $\\scriptsize N^K \\times N^K$\n",
    "* $G \\sim \\Phi$ which is a set of independent binomial distributions on the occurrence of edges\n",
    "* We assume a set of $\\theta_k$ make up the $\\Phi$ through successive kronecker products\n",
    "    \n",
    "    $\\Phi   = \\theta^{(1)}\\otimes \\theta^{(2)} \\otimes \\dots \\theta^{(k)} \\dots \\otimes \\theta^{(K)}$\n",
    "* If we assume the sizes of each of these $\\theta^{(k)}$ are fixed to $N\\times N$, then $\\Phi_{N^K\\times N^k}$\n",
    "* Further according to our mixture model we allow each $\\theta^{(k)}$ to be of a particular \"basis\" or \"class\". That is  $\\theta^{(k)} \\in [\\theta_1, \\theta_2, \\dots, \\theta_c, \\dots, \\theta_C]_{C\\rightarrow\\infty}$ because we want to model that $\\theta^{(k)}$ is drawn from a continuous distribution as shown in our mixture model.\n",
    "    \n",
    "    For example $\\theta^{(2)}_4$ is a basis $\\theta$ belonging to a class with label 4 and has the index 2 in the sequence of kronecker multiplications to obtain $\\Phi$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections we implement the above mixture model in pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose two log-normal distributions which generate $\\alpha_k$ and $\\beta_k$ values for every $k \\in K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should come from another source which computes how many kronecker products are needed\n",
    "# K   = tf.placeholder(tf.int32) # Incorrect because cant unfurl as a graph on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from separate log-normal distributions to get K number of values for alpha and beta\n",
    "# Setup parameters\n",
    "sig_a = tf.placeholder_with_default([1.0], [1]) # skew parameter TUNE\n",
    "sig_b = tf.placeholder_with_default([1.0], [1]) # skew parameter TUNE\n",
    "mean_a  = tf.placeholder_with_default([0.0], [1]) # mean parameter TUNE\n",
    "mean_b  = tf.placeholder_with_default([0.0], [1]) # mean parameter TUNE\n",
    "# Make log-normal distributions\n",
    "# alpha_batch_shape = beta_batch_shape    = K\n",
    "gamma_a   = tfd.LogNormal(loc=mean_a, scale=sig_a, name=\"LogNormal-Alphas\")\n",
    "gamma_b   = tfd.LogNormal(loc=mean_b, scale=sig_b, name=\"LogNormal-Betas\")\n",
    "# Sample from these distributions\n",
    "alpha_batch   = gamma_a.sample(K_)\n",
    "beta_batch    = gamma_b.sample(K_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a batch of $K$ Beta distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build K number of Beta distributions from alpha and beta values\n",
    "mu_batch   = tfd.Beta(alpha_batch, beta_batch, name='kBetaDistb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the $K$ Beta distributions produce the $N\\times N$ number of $\\theta_{ij}$ elements for their corresponding $\\theta^{(k)}_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get theta_ij values for every theta_k from the corresponding mu_k\n",
    "theta_k_shape   = tf.placeholder(tf.int32, (2,))\n",
    "theta_c_set     = tf.squeeze(mu_batch.sample(sample_shape=theta_k_shape, name=\"theta_set\"), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from mu_k for theta_ij values\n",
    "\n",
    "# alpha  = tf.placeholder_with_default([1.0], [1])\n",
    "# beta   = tf.placeholder_with_default([1.0], [1])\n",
    "# mu_batch_shape   = tf.placeholder(tf.int32)\n",
    "# p_mu   = tfd.Beta(alpha, beta, name='Mu_distb')\n",
    "# mu_batch  = tf.squeeze(p_mu.sample(mu_batch_shape),axis=2)\n",
    "# theta_c   = mu_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the mu samples as thresholds for \n",
    "# theta Bernoulli distributions of edges\n",
    "\n",
    "# theta_c_distb = tfd.Bernoulli(probs=mu_batch, name='theta_c') # Actually never used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kronecker multiply to obtain the threshold values for $\\Phi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoiseScale   = tf.placeholder_with_default(0.01,[])   \n",
    "phi_batch    = addNoise2Mat(theta_c_set[...,0])\n",
    "for k in range(1,K_):\n",
    "    # Add noise to the theta\n",
    "#     print(k)\n",
    "    ktheta_c   =  addNoise2Mat(theta_c_set[...,k], std=NoiseScale)\n",
    "    # Do kronecker product\n",
    "    phi_batch   = kronecker_product(phi_batch, ktheta_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample from the $\\Phi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pk_c_distb   = tfd.Bernoulli(probs=Pk_c, name='Pk_c')\n",
    "# G_c          = Pk_c_distb.sample(NumSamples)\n",
    "\n",
    "Phi   = tfd.Bernoulli(probs=phi_batch, name='Phi')\n",
    "G_c   = Phi.sample(NumSamples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# [G, Pk_c_s, theta_c,\n",
    "# alphas, betas, theta_c_set] = sess.run([G_c, Phi, mu_batch, alpha_batch, beta_batch, theta_c_set], \n",
    "#                                 feed_dict={K:K_,\n",
    "#                                            mu_batch_shape:theta_shape_,\n",
    "#                                            theta_k_shape:theta_shape_,\n",
    "#                                            alpha:alpha_,\n",
    "#                                            beta:beta_,\n",
    "#                                           })\n",
    "\n",
    "[G_c_] = sess.run([G_c],\n",
    "             feed_dict={\n",
    "                 NoiseScale:NoiseScale_,\n",
    "                 theta_k_shape:theta_shape_,\n",
    "             })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 1 0 0]\n",
      "  [0 0 0 ... 0 0 1]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 1 0]\n",
      "  [0 0 0 ... 0 0 1]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 1]\n",
      "  [0 0 0 ... 0 1 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 1 0 0]\n",
      "  [0 0 0 ... 0 0 1]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(G_c_)\n",
    "# print(theta_c)\n",
    "# print(theta_c_set)\n",
    "# print(np.shape(theta_c_set))\n",
    "# print(Pk_c_s.shape)\n",
    "# print(G.shape)\n",
    "# print(alphas)\n",
    "# print(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e8981512315e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'theta_c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'theta_c' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(theta_c)\n",
    "plt.title('theta_c')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Pk_c_s)\n",
    "plt.title('P_k_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('All samples')\n",
    "r = np.floor(np.sqrt(NumSamples))\n",
    "c = np.ceil(float(NumSamples)/r)\n",
    "for i in range(0,NumSamples):\n",
    "    plt.subplot(r,c,i+1)\n",
    "    plt.spy(G[i,:], markersize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
