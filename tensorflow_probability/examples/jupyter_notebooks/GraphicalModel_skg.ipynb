{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# import collections\n",
    "# tfe = tf.contrib.eager\n",
    "# try:\n",
    "#   tfe.enable_eager_execution()\n",
    "# except ValueError:\n",
    "#   pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_0$ : Make a batch of bernoulli distributions and draw samples from it $G_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"theta_0/sample/Reshape:0\", shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "theta_0 = tfd.Bernoulli(probs=[[0.9, 0.4],[0.3, 0.9]], name='theta_0')\n",
    "G_0 = theta_0.sample()\n",
    "\n",
    "print(G_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "G_0 = sess.run(G_0)\n",
    "print(G_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following method computes the Kronecker product two matrices. The convention is usually backwards that mat2 is scaled and block replicated on mat1 elementwise. Here lines are changed so that mat1 is scaled and block replicated on mat2. This is inline with the paper conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kronecker_product(mat1, mat2):\n",
    "    m1 = tf.shape(mat1)[0]\n",
    "    n1 = tf.size(mat1) // m1\n",
    "    m2 = tf.shape(mat2)[0]\n",
    "    n2 = tf.size(mat2) // m2\n",
    "#     mat1_rsh =tf.reshape(mat1, [m1, 1, n1, 1])\n",
    "    mat2_rsh =tf.reshape(mat1, [1, m1, 1, n1])\n",
    "#     mat2_rsh =tf.reshape(mat2, [1, m2, 1, n2])\n",
    "    mat1_rsh =tf.reshape(mat2, [m2, 1, n2, 1])\n",
    "    return tf.reshape(mat1_rsh*mat2_rsh, [m1 * m2, n1 * n2])\n",
    "#     return tf.reshape(tf.reshape(mat1_rsh * mat2_rsh, [m1 * m2, n1 * n2]),[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE for kronecker product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  0.,  4.,  0.],\n",
       "       [ 3.,  0.,  4.,  0.],\n",
       "       [ 5.,  0.,  6.,  0.],\n",
       "       [ 5.,  0.,  6.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = kronecker_product(a,b)\n",
    "\n",
    "p = [[1.,0],[1.,0]]\n",
    "q = [[3,4],[5.,6.]]\n",
    "# c = sess.run(c, feed_dict={a:[[1.,0],[1.,0]], b:[[3.,4.],[5.,6.]]})\n",
    "out = sess.run(c, feed_dict={a:p, b:q})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each $\\theta_c$ make a matching batch of random Gaussian noise variables, given the $\\theta_c$ matrix size: $\\eta_c$. This will be the additive noise for each $\\theta_c$ at each stage of kronecker multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise2Theta(theta_c, mean=0, std=0.01, NRMLZ=True):\n",
    "    # Set the seed so the results are reproducible.\n",
    "    np.random.seed(123)\n",
    "    # Make distribution, sample and add\n",
    "    p_eta = tfd.Normal(loc=mean, scale=std, name='AdditiveEdgeNoise')\n",
    "    eta_c = p_eta.sample(tf.shape(theta_c))\n",
    "    theta_c_noise = theta_c + eta_c\n",
    "    # Make sure values do not run off\n",
    "    # Clip values out of [0,1]\n",
    "    if NRMLZ:\n",
    "        theta_c_noise_nrml   = tf.maximum(tf.minimum(theta_c_noise,1),0)\n",
    "        return theta_c_noise_nrml\n",
    "    else:\n",
    "        return theta_c_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE for noisy $\\theta_c$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   7.23697085e-05]\n",
      " [  9.90425408e-01   1.50220341e-03]]\n"
     ]
    }
   ],
   "source": [
    "theta   = tf.placeholder(tf.float32)\n",
    "theta_noisy = addNoise2Theta(theta)\n",
    "p = np.array([[1.,0],[1.,0]])\n",
    "out = sess.run(theta_noisy, feed_dict={theta:p})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.179107    0.11355007]\n",
      " [ 0.07164492 -0.11725985]]\n",
      "[[ 0.82089299  0.11355007]\n",
      " [ 1.0716449  -0.11725985]]\n",
      "[[ 0.82089299  0.11355007]\n",
      " [ 1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Junk trials - can be ignored\n",
    "Pk = tf.placeholder(tf.float32)\n",
    "\n",
    "mean = 0\n",
    "std = 0.1\n",
    "p_eta = tfd.Normal(loc=mean, scale=std, name='AdditiveEdgeNoise')\n",
    "eta = p_eta.sample(tf.shape(Pk))\n",
    "probs = Pk + eta\n",
    "probs_n = tf.maximum(tf.minimum(probs,1),0)\n",
    "# a = tf.constant(Pk)\n",
    "\n",
    "# Eta = tfd.Normal(loc=np.repmat([0], Theta), scale=, name='EdgeNoise_small')\n",
    "\n",
    "[probs_n, probs, eta_] = sess.run([probs_n, probs, eta], feed_dict={Pk:[[1.,0],[1.,0]]})\n",
    "print(eta_)\n",
    "print(probs)\n",
    "print(probs_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to generate a sample set of $\\mu$s. These $\\mu$s come from the same $\\beta$-distribution. The \n",
    "samples for $\\mu$ are the threshold values for the Bernoulli distributions in a single $\\theta_c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31504449,  0.67142296],\n",
       "       [ 0.51679528,  0.70658988]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_shape   = tf.placeholder(tf.int32)\n",
    "alpha  = tf.placeholder_with_default([1.0], [1])\n",
    "beta   = tf.placeholder_with_default([1.0], [1])\n",
    "p_mu   = tfd.Beta(alpha, beta, name='Mu_distb')\n",
    "mu     = tf.squeeze(p_mu.sample(theta_shape),axis=2)\n",
    "\n",
    "mu_out  = sess.run(mu, feed_dict={theta_shape:[2,2]})\n",
    "mu_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Need a markov chain specification for the alphas that parameterise the $\\beta$-distribution for $\\mu$.\n",
    "* Need to connect all the distributions\n",
    "* Parameterise $N_c$ --> size of square $\\theta_c$ matrix\n",
    "* Parameterise $K_c$ --> which is the number of kronecker products $\\theta_c$ undergoes in the kronecker sequence\n",
    "* How to connect (smoothness) between consecutive $\\theta$s or $P_k$s? \n",
    "    * Markov relationship between the consecutive $\\alpha$s\n",
    "    * Connect $P_c$ to $P_{c+1}$ through some conditional distribution\n",
    "    * Connect $P_c$ to $\\theta_{c+1}$ through some conditional distribution\n",
    "    * Do some statistics on $P_c$ to change distribution for $\\mu_{c+1}$ by altering $\\alpha_{c+1}$ or $\\beta_{c+1}$\n",
    "\n",
    "> Is it not important then to preserve the order of $\\theta_c$s in the kronecker sequence? The smoothness should propagate to the relevant next layers of abstractions.\n",
    "\n",
    "* Implement permutation and additive noise for edges from SKG paper.\n",
    "\n",
    "### Questions to answer:\n",
    "* Sample from the distributions to generate graphs G. Do they look good?\n",
    "* Compute log likelihoods. Verification of likelihoods holds?\n",
    "* Does inference work?\n",
    "* What is the improvement over the permutation space?\n",
    "* What kind of data should we test this on?\n",
    "* Check out the datasets used in SKG paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "* Stick breaking distribution for $K$\n",
    "* Prime factor decomposition for $N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical stuff\n",
    "* Bridge the gap between TFP implementation and log likelihood computation in SKG\n",
    "* Carl tutorial for inference\n",
    "* TFP tutorial for covariance matrix extimation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
